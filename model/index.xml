<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Models on Med-Eval</title>
    <link>https://dujh22.github.io/model/</link>
    <description>Recent content in Models on Med-Eval</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 03 Jan 2024 18:14:28 +0800</lastBuildDate>
    <atom:link href="https://dujh22.github.io/model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Med Eval测评结果</title>
      <link>https://dujh22.github.io/model/med-eval%E6%B5%8B%E8%AF%84%E7%BB%93%E6%9E%9C/</link>
      <pubDate>Wed, 03 Jan 2024 18:14:28 +0800</pubDate>
      <guid>https://dujh22.github.io/model/med-eval%E6%B5%8B%E8%AF%84%E7%BB%93%E6%9E%9C/</guid>
      <description>Med-Eval-Chinese Doctor 模型 基座 数据 得分 Doctor Baichuan2-13B-Chat 2.23125GB PT数据集epoch=1.0,loss=2.1348 60.06MB SFT数据epoch=2.5，loss~2.00 32.22% 31.82% 31.86% AiMed Baichuan2-13B-Chat 215.3MB PT数据集 epoch=1.0,loss=2.332 48.03MB SFT数据epoch=4.0,loss~1.900 23.43% 23.79% 23.40% Baichuan2-13B-Chat - - 13.64% 13.57% 13.53% 带有prompt工程后：&#xA;指标 指标含义 Doctor AiMed total_questions 总问题数 2773 2773 strict_correct_answers 严格得分 1087 786 Model Strict Accuracy 严格得分率 39.20% 28.34% loose_correct_answers 绝对宽松得分 1583 1107 Model Loose Accuracy 绝对宽松得分率 57.09% 39.92% loose_correct_answers2 相对宽松得分 1594 1177 Model Loose Accuracy2 相对宽松得分率 57.48% 42.45% error_answers 错误 1179 1596 Model Error 错误率 42.</description>
    </item>
    <item>
      <title>MedRad具体场景和代码</title>
      <link>https://dujh22.github.io/model/medrad%E5%85%B7%E4%BD%93%E5%9C%BA%E6%99%AF%E5%92%8C%E4%BB%A3%E7%A0%81/</link>
      <pubDate>Wed, 03 Jan 2024 12:22:42 +0800</pubDate>
      <guid>https://dujh22.github.io/model/medrad%E5%85%B7%E4%BD%93%E5%9C%BA%E6%99%AF%E5%92%8C%E4%BB%A3%E7%A0%81/</guid>
      <description>低复杂度：医学知识问答 1. 场景示例 { &amp;#34;QU&amp;#34;: &amp;#34;以下都是治疗病态肥胖的手术选择，除了-&amp;#34;, &amp;#34;OP&amp;#34;: { &amp;#34;A&amp;#34;: &amp;#34;可调节胃束带&amp;#34;, &amp;#34;B&amp;#34;: &amp;#34;胆胰分流&amp;#34;, &amp;#34;C&amp;#34;: &amp;#34;十二指肠开关&amp;#34;, &amp;#34;D&amp;#34;: &amp;#34;Roux en y十二指肠旁路&amp;#34; }, &amp;#34;EXP&amp;#34;: &amp;#34;Ans.是“d”，即Roux en Y十二指肠旁路减肥手术程序包括：a。垂直带状腹足虫。可调节胃束带。Roux-en-Y胃旁路术（非Roux-en-Y-十二指肠旁路术）d。胆胰分流。十二指肠切除术病态肥胖的外科治疗被称为减肥手术。病态肥胖被定义为体重指数为35 kg/m2或以上，伴有肥胖相关的合并症，或BMI为40 kg/m2或更大，没有合并症。减肥手术导致体重减轻是由两个因素造成的。一是限制饮食。另一种是摄入食物的吸收不良。o胃限制性手术包括垂直带状胃成形术和可调节胃束带术o吸收不良手术包括胆胰分流，十二指肠切换器Roux-en-Y胃旁路既有限制性又有吸收不良的特点减肥手术：作用机制限制性垂直胃束带腹腔镜可调节胃束带大范围限制性/轻度吸收不良Roux-en-Y胃旁路大范围吸收不良/轻度限制性胆胰分流&amp;#34;, &amp;#34;AN&amp;#34;: &amp;#34;D&amp;#34; },2. 场景说明 这个例子是一个医学知识问答场景，其中包含一个多项选择题，目的是识别出不属于治疗病态肥胖手术选择的选项。这种类型的问题通常要求对特定医学领域有深入了解。要处理这类场景，可以从RAG (Retrieval-Augmented Generation) 结合CoT (Chain of Thought) 和Agent的角度来考虑。&#xA;信息检索（RAG）: 首先使用信息检索技术从大量数据中找到与问题相关的信息。这一步骤的目的是快速定位与问题相关的医学知识和数据。&#xA;思维链（CoT）: 接下来，通过构建思维链来分析问题。这包括理解问题的具体要求，解析各个选项，并将其与检索到的信息相对比。这一步骤有助于深入理解问题的背景和每个选项的含义。&#xA;智能代理（Agent）: 最后，结合Agent的能力，对上述两步骤的结果进行综合分析，并得出最终答案。Agent在这里起到的是决策和验证的作用，确保答案的准确性和逻辑性。&#xA;对于这个特定的例子，Agent首先需要识别问题是关于病态肥胖的治疗手术，然后通过RAG检索相关的医学信息，比如各种手术的类型和特点。通过CoT分析每个选项，理解它们各自的手术原理，并确定哪个选项不属于治疗病态肥胖的手术。最后，Agent将结合这些信息来验证并确定正确的答案。&#xA;3. MedRad实现 医学知识问答系统的工作步骤：&#xA;问题识别：&#xA;Agent接收到用户的查询（医学问题）后，首先进行问题识别。这个过程可能包括关键词提取、问题类型分类（例如症状查询、药物信息或疾病相关知识）以及紧急度评估。 信息检索：&#xA;Agent使用先进的信息检索技术在大量医学数据中找到与问题最相关的信息。这些数据可能来自医学数据库、研究论文、临床指南或其他医学知识库。 选项解析与对比：&#xA;对于问题的每个可能选项（A、B、C、D），Agent分别进行解析。这个解析可能包括对医学术语的理解、病理机制、治疗方案或药物作用的解释等。 Agent将每个选项与检索到的相关信息进行对比，评估其准确性、相关性和可靠性。 综合分析：&#xA;Agent对上述每个步骤的结果进行综合分析。这可能涉及比较不同选项的支持证据，考虑其医学逻辑和临床实践的一致性。 分析可能还包括检查信息源的可信度、最新度以及与现有医学共识的一致性。 得出结论：&#xA;经过综合分析后，Agent得出最终答案。这个答案是基于Agent对各个选项评估的结果，选择最佳的、最符合医学证据的选项。 最终答案会反馈给用户，并提供相应的解释，解释可能包括答案的依据、相关的医学信息以及如果可行的话，进一步的建议或指示。 这个流程涵盖了从接收用户查询到提供经过深思熟虑的、信息支持的答案的整个过程。在实际应用中，Agent还会包括额外的功能，如与用户的交互能力、处理模糊或不完整查询的能力，以及持续学习和适应新信息的能力。&#xA;以下是该功能实现的伪代码：&#xA;function handle_medical_query(query) agent = initialize_agent() # 使用信息检索技术检索相关信息 related_information = retrieve_information(query) # 解析每个选项，并与检索到的信息进行比较 option_A_result = agent.</description>
    </item>
    <item>
      <title>MedRad:一个医学大模型的可靠辅助决策框架</title>
      <link>https://dujh22.github.io/model/medrad%E4%B8%80%E4%B8%AA%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E9%9D%A0%E8%BE%85%E5%8A%A9%E5%86%B3%E7%AD%96%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Wed, 03 Jan 2024 12:22:31 +0800</pubDate>
      <guid>https://dujh22.github.io/model/medrad%E4%B8%80%E4%B8%AA%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%AF%E9%9D%A0%E8%BE%85%E5%8A%A9%E5%86%B3%E7%AD%96%E6%A1%86%E6%9E%B6/</guid>
      <description>摘要: 随着医学领域数据的激增和临床决策的复杂性增加，需要强大的计算工具来辅助医生作出准确、可靠的决策。虽然现有研究已经在准确性上取得进展，但大模型在可靠性和稳定性方面的不足显而易见。为此，我们提出了MedRad框架，一个结合深度知识工程、Chain of Thought (CoT) 推理、Retrieval-Augmented Generation (RAG) 技术和智能代理（Agent）的系统，以提高决策的可靠性。本研究的早期阶段集中于构建医学领域的大型语言模型和通用模型训练算法。进一步，我们将重点转向如何在医学知识问答、门诊对话和临床病历诊断等具有不同复杂度的场景中利用这些技术实现高可靠性的医学决策。实验结果显示，MedRad在上述场景中能够提供高质量的决策路径。我们的框架通过与基座模型的松耦合设计，展现了在不同医学场景中的强大适应性。&#xA;关键词: 医学大模型、决策支持系统、可靠性、Chain of Thought、Retrieval-Augmented Generation、Agent&#xA;1. 引言 在医学领域，高质量的决策是病人健康和生命的守护者。医生们经常面临着需要在短时间内处理大量信息并做出关键决策的压力。这种决策的复杂性由于医疗数据的海量增长和临床案例的多变性而不断增加。传统的决策支持系统，在处理标准化流程时效果显著，但在解读非结构化的医疗数据、处理复杂病例以及适应不断演变的医学知识面前则显得力不从心。这些系统在准确解释临床数据、适应新的治疗协议以及应对罕见病症方面，常常表现出灵活性不足和可靠性不高的问题。&#xA;随着人工智能的迅速发展，机器学习和大数据分析已被引入到决策支持工具中，以增强它们处理复杂数据的能力。这些技术在提升诊断精度和治疗效率方面取得了一定的成就，尤其是在图像识别和预测建模领域。然而，仅有的准确性并不足以应对医学领域的全部挑战。现有的人工智能系统通常是针对特定任务设计的，缺乏足够的灵活性来适应医学领域不断变化的需求和复杂的临床场景。此外，这些系统在解释能力和决策透明度方面往往存在不足，这限制了它们在临床实践中的应用，因为医疗专业人员和患者都需要理解决策背后的逻辑。此外，随着医疗实践越来越依赖数据驱动的方法，医生和医疗专业人员的角色正在发生变化，他们需要能够信任并理解这些工具提供的信息和建议。&#xA;正是基于这些挑战，我们开发了MedRad框架。MedRad不仅着重于提升决策的准确性，而且特别强调在保持这种准确性的同时增强决策的可靠性和稳定性。通过结合最新的人工智能技术，如深度学习、自然语言处理，和医学知识工程，MedRad旨在创建一个更加智能和适应性强的决策支持系统。该系统不仅能够处理和分析复杂的医疗数据，还能在提供决策时给出清晰、可解释的逻辑路径，使医生能够更好地理解和信任其提供的建议。通过这种方式，MedRad框架寻求成为医疗专业人员的一个真正的合作伙伴，支持他们在日益复杂的医疗环境中做出更好的决策。&#xA;2. 相关工作 本节回顾了医学决策支持系统的发展历程，以及大模型在医学领域的应用现状。我们将探讨现有模型在处理医学数据时的局限性，尤其是在稳定性和可靠性方面的不足，并分析了Chain of Thought (CoT) 推理和Retrieval-Augmented Generation (RAG) 技术对于提高医学决策质量的潜在贡献。&#xA;2.1 医学决策支持系统的发展 医学决策支持系统（CDSS）的历史可以追溯到20世纪70年代，当时的系统主要基于规则的推理来辅助临床决策。随着时间的推移，这些系统逐渐集成了更复杂的算法，包括基于知识的系统和基于数据的机器学习方法。在21世纪初，随着计算能力的提升和电子健康记录（EHR）的普及，CDSS开始利用大数据进行更复杂的预测和分析。尽管这些系统在处理标准化数据方面取得了显著进展，但在解释非结构化医疗数据、适应新的临床实践和医学知识时，它们仍显示出局限性。&#xA;2.2 大模型在医学领域的应用 近年来，随着深度学习技术的发展，大型预训练模型，如GPT和BERT，已经开始在医学领域中发挥作用。这些模型能够处理大量非结构化的医疗文本数据，提供更深入的见解和预测。例如，它们被用于自动化病历摘要、医学文献分析、疾病预测以及提供个性化的患者护理建议。然而，这些大型模型在处理高度专业化的医学知识时仍然面临挑战，尤其是在理解复杂医学术语和临床指南方面。&#xA;2.3 医学决策的稳定性和可靠性 尽管大型模型在处理医学数据方面显示出潜力，但其在确保决策稳定性和可靠性方面存在不足。这主要是由于这些模型在训练过程中缺乏对医学领域特定知识的深入理解。此外，这些模型通常缺乏足够的透明度，使得医疗专业人员难以理解和信任其决策过程和结果。因此，需要开发更加先进的方法来提高这些系统在医学决策中的稳定性和可靠性。&#xA;2.4 Chain of Thought (CoT) 推理和Retrieval-Augmented Generation (RAG) 技术 CoT推理技术通过模拟医生的思考过程来增强决策的逻辑性和透明度。通过将决策过程分解为一系列逻辑步骤，CoT提供了一种更加直观和可解释的方式来解释模型的推理过程。另一方面，RAG技术通过结合强大的检索能力和生成能力来增强模型对医学知识的理解。这种方法允许模型在做出决策前，先从大量医学数据中检索相关信息，从而提高其决策的准确性和深度。结合这两种技术，可以显著提高医学决策支持系统的性能，尤其是在处理复杂和非标准化的临床情况时。&#xA;综上所述，尽管当前的医学大模型在处理特定类型的医疗数据方面取得了进展，但在提高医学决策的稳定性和可靠性方面还有很长的路要走。&#xA;3. MedRad框架 本节详细介绍MedRad框架的架构和工作原理。我们将解释如何结合CoT、RAG和Agent技术来挖掘大型语言模型的潜力，并描述这一多模块系统是如何协同工作以提升决策质量的。&#xA;框架图：&#xA;https://gitee.com/dujh22/pic/raw/master/MedRad.png&#xA;详细见本目录下的：“MedRad具体场景和代码”&#xA;注意：由于本项目前一版本的论文还未完成：MedRad: 一个医学大模型的可靠辅助决策框架&#xA;谷歌云盘链接： https://drive.google.com/file/d/1fqFGu4y3uhspXWeRlqiCsBHsl_NjNaen/view?usp=sharing&#xA;百度网盘链接: https://pan.baidu.com/s/1qeWx2RrwiErLc8vVXS0pBA?pwd=2024 提取码: 2024&#xA;下面是新一版本未完成的论文，后续会持续更新，请进一步关注！&#xA;4. 方法 我们将说明我们如何构建医学领域的大型语言模型，包括数据准备、预处理、模型训练和微调的步骤。此外，我们将详细描述如何应用CoT和RAG技术来辅助模型进行复杂决策。&#xA;5. 实验设计 本节概述了实验的设计，包括选择的医学场景、评估标准和实验设置。我们将详细说明如何在不同复杂度的医学场景中进行实验以评估MedRad框架的效果。</description>
    </item>
    <item>
      <title>医学大模型榜单V2</title>
      <link>https://dujh22.github.io/model/%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%9C%E5%8D%95v2/</link>
      <pubDate>Wed, 03 Jan 2024 12:18:27 +0800</pubDate>
      <guid>https://dujh22.github.io/model/%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%9C%E5%8D%95v2/</guid>
      <description>模型名称 模型类型 支持语言 参数规模 发布机构 模型最后一次更新时间 简介 GitHub地址 Hugging Face 地址 论文地址 官网地址 其它信息来源 API 是否可用 API 使用地址 是否可以私有化部署 Demo 地址 上下文长度 训练用数据 训练基座 是否可商用 gpt-4-1106-preview 通用 多语言 1.8T (未证实) OpenAI 2023.11.6 GPT-4，或称Generative Pre-trained Transformer 4，是由OpenAI开发的最先进的语言模型。它的参数量大概是其前身GPT-3的10倍。这一进步使GPT-4能够以惊人的准确性和细微差别理解和生成类似人类的文本。它擅长各种任务，如回答问题、写文章、总结文本等等。它在不同数据集上进行大规模训练，能够深入理解多种语言和科目，使其成为人工智能驱动应用程序中的通用工具。 无 无 无 https://platform.openai.com/docs/overview 到处都有 付费，输入/输出 1k token 花费 0.01$/0.03$ https://platform.openai.com/docs/api-reference 否 https://chat.openai.com/ 128K 未公布 无 是 gpt-3.5-turbo-1106 通用 多语言 175B (未证实) OpenAI 2023.11.6 GPT-3.5是OpenAI开发的先进自然语言处理模型，作为GPT-3系列的改进版本。它继承了GPT-3的基本架构，拥有数以百亿计的参数，能够更有效地处理和生成自然语言文本。GPT-3.5在理解复杂语境、回答问题、撰写文章和文本摘要方面表现出色。通过广泛的数据训练，GPT-3.5能够处理多种语言和领域的内容，是人工智能应用中的多功能工具。 无 无 无 https://platform.openai.com/docs/overview 到处都有 付费，输入/输出 1k token 花费 0.</description>
    </item>
    <item>
      <title>医学大模型榜单</title>
      <link>https://dujh22.github.io/model/%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%9C%E5%8D%95/</link>
      <pubDate>Wed, 20 Dec 2023 19:37:38 +0800</pubDate>
      <guid>https://dujh22.github.io/model/%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%9C%E5%8D%95/</guid>
      <description>模型 所在机构 发布时间 开源地址 所用数据 Med-Flamingo 一种适用于医学领域的多模态少样本学习器 美国斯坦福大学- -基于OpenFlamingo-9B -对出版物和教科书中成对和交错的医学图像-文本数据进行预训练-4K数据集 BioMedLM（原PubMed GPT 2.7B） 用于生物医学文本的特定领域大型语言模型 美国斯坦福大学-基础模型研究中心CRFM 2022年12月 https://github.com/stanford-crfm/BioMedLM -基于HuggingFace GPT模型 -2.7B的参数和1024个标记的最大上下文长度 -数据是Pile数据集的部分——PubMed Abstracts和PubMed Central：涵盖由美国国立卫生研究院策划的来自生物医学文献的 16 万份摘要和 5 万篇全文文章的集合 BioGPT 大规模生物医学文献上进行预训练的特定领域生成式 Transformer 语言模型 微软 https://github.com/microsoft/BioGPT -GPT2作为骨干模型 -从 PubMed 收集文章，PubMed 是一个生物医学研究领域的大型数据库，团队共产生1500万条带有标题和摘要的内容 -使用 3.57 亿个参数改进了预训练的基于 GPT-2 的模型，用于下游任务：端到端关系提取、文本生成、问题回答和文档分类 Med-PaLM2 5400亿参数的转换器语言模型 谷歌 文心一言 百度 2023年2月 对中国医疗信息数据提供商GBI Health的并购，通过GBI与其类ChatGPT产品“文心一言”等的结合 BioMedGPT-1.6B 生物医药领域基础模型 清华大学-智能产业研究院 2023年4月19日 -把分子语言中蕴含的知识以及长期以来通过实验总结的文本和知识图谱信息融合压缩到一个大规模语言模型中，从而实现从序列模式中学习生物结构和功能规律，通过AI解码生命语言 OpenBioMed 清华大学-智能产业研究院 2023年8月14日 https://github.com/BioFM/OpenBioMed -基于Llama2的大型生成语言模型 -从Llama2-7B-Chat与S2ORC语料库中的数百万篇生物医学论文进行了微调 -开源轻量版BioMedGPT, 知识图谱&amp;amp;20+生物研究领域多模态预训练模型 本草Huatuo 哈尔滨工业大学 2023年3月31日 https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese -经过中文医学指令精调/指令微调(Instruct-tuning) 的LLaMA-7B模型 -医学知识图谱和GPT3.</description>
    </item>
    <item>
      <title>通用大模型榜单</title>
      <link>https://dujh22.github.io/model/%E9%80%9A%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%9C%E5%8D%95/</link>
      <pubDate>Wed, 20 Dec 2023 18:47:46 +0800</pubDate>
      <guid>https://dujh22.github.io/model/%E9%80%9A%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%A6%9C%E5%8D%95/</guid>
      <description> 模型 开源地址 参数规模 所用数据 ChatGLM-6B https://github.com/THUDM/ChatGLM-6B 62亿 1T 标识符的中英双语训练 ChatGLM2-6B https://github.com/THUDM/ChatGLM2-6B 1.4万亿中英文tokens数据集上训练，并做了模型对齐+SFT GLM-130B https://github.com/THUDM/GLM-130B 1300亿 4000 亿个文本token训练+SFT Chinese-LLaMA-Alpaca https://github.com/ymcui/Chinese-LLaMA-Alpaca 在原版LLaMA的基础上扩充了中文词表并使用了中文数据进行二次预训练 Moss https://github.com/OpenLMLab/MOSS 七千亿中英文以及代码单词上预训练 baichuan-7B 1.2万亿tokens上训练的70亿参数模型，支持中英双语，上下文窗口长度为4096 AquilaChat-7B {{https://mp.weixin.qq.com/s/XkoLnFycG1jPWrNT3w_p-g}} CPM-Bee https://zhuanlan.zhihu.com/p/639459740 MPT-30b https://www.bilibili.com/video/BV1UW4y1D7N9/?share_source=copy_web </description>
    </item>
    <item>
      <title>全球开源开放大模型发展情况</title>
      <link>https://dujh22.github.io/model/%E5%85%A8%E7%90%83%E5%BC%80%E6%BA%90%E5%BC%80%E6%94%BE%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E6%83%85%E5%86%B5/</link>
      <pubDate>Tue, 19 Dec 2023 14:43:38 +0800</pubDate>
      <guid>https://dujh22.github.io/model/%E5%85%A8%E7%90%83%E5%BC%80%E6%BA%90%E5%BC%80%E6%94%BE%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E6%83%85%E5%86%B5/</guid>
      <description>开源开放的大模型 旨在记录全球开源开放大模型发展情况&#xA;基础大模型 序号 名称 参数规模 数据规模 说明 1 LLaMA-2 7B,13B,34B,70B 2T 可商用 2 Falcon 7B,40B,180B 3.5T 数据集 RefinedWeb 3 baichuan-2 7B,13B 2.6T 开放，商用需授权，baichuan-1 4 InternLM 7B,20B 2.3T 开放，商用需授权 5 BLOOM 3B,7.1B,176B 366B 可商用，最为宽松，详细介绍 6 GALACTICA 6.7B,30B,120B 106B 开放的科学文本和数据 7 LLaMA 7B,13B,30B,65B 1.4T Meta，代码开源，模型“泄露”,不可商用，详细介绍 8 MOSS-moon 16B 700B 6.67x1022 FLOPs 9 ChatGLM2 6B 1.4T 10 StableLM 3B,7B 800B 11 RedPajama-INCITE 3B,7B 1T 12 GPT-NeoX 20B 3.15M 800GB的The Pile数据集 13 OpenLLaMA 3B,7B,13B 1T 14 MPT 7B,30B 1T 15 Pythia 2.</description>
    </item>
  </channel>
</rss>
